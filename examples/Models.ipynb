{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Radiant MLHub Logo](https://radiant-assets.s3-us-west-2.amazonaws.com/PrimaryRadiantMLHubLogo.png)](https://mlhub.earth/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "This notebook will walk you through a few common techniques for working with Radiant MLHub model, including:\n",
    "\n",
    "* Listing available models\n",
    "* Fetching a model\n",
    "* Fetching assets and collections associated with a model\n",
    "\n",
    "A **Model** in the Radiant MLHub API is a STAC item implementing the\n",
    "[ML Model extension](https://github.com/stac-extensions/ml-model).\n",
    "The goal of the STAC ML Model Extension is to provide a way of cataloging \n",
    "machine learning (ML) models that operate on Earth observation (EO) data \n",
    "described as a STAC catalog.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import itertools as it\n",
    "\n",
    "from radiant_mlhub import MLModel, client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `MLModel` Class\n",
    "\n",
    "Using the `radiant_mlhub.MLModel` class is the recommended method for working with models as Python objects (see [Low-Level Client](#Low-Level-Client) docs below for how to work with raw API responses). The `MLModel` class has some convenient methods for listing and fetching models, as well as fetching the assets associated with those models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Models\n",
    "\n",
    "You can use the `MLModel.list` class method to list all models available through the Radiant MLHub API. Each instance has `id` and `title` attributes that you can inspect to get more information about the model, and an `assets` property that you can use to get the links associated with the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigEarthNet (bigearthnet_v1)\n",
      "Chesapeake Land Cover (microsoft_chesapeake)\n",
      "CV4A Kenya Crop Type Competition (ref_african_crops_kenya_02)\n",
      "Dalberg Data Insights Crop Type Uganda (ref_african_crops_uganda_01)\n",
      "Great African Food Company Crop Type Tanzania (ref_african_crops_tanzania_01)\n",
      "LandCoverNet (landcovernet_v1)\n",
      "Open Cities AI Challenge (open_cities_ai_challenge)\n",
      "PlantVillage Crop Type Kenya (ref_african_crops_kenya_01)\n",
      "Semantic Segmentation of Crop Type in Ghana (su_african_crops_ghana)\n",
      "Semantic Segmentation of Crop Type in South Sudan (su_african_crops_south_sudan)\n"
     ]
    }
   ],
   "source": [
    "models = MLModel.list()\n",
    "\n",
    "# List the title and ID of first 10 datasets returned by the API\n",
    "for model in models:\n",
    "    print(f'{dataset.title} ({dataset.id})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch a Dataset\n",
    "\n",
    "If you know the ID of a dataset, you can also fetch it directly using the `Dataset.fetch` method. This method returns a `Dataset` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spacenet 1\n"
     ]
    }
   ],
   "source": [
    "spacenet1_dataset = Dataset.fetch('spacenet1')\n",
    "\n",
    "print(spacenet1_dataset.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dataset Collections\n",
    "\n",
    "Once you have a dataset, you can list its collections. Datasets are comprised of 1 or more collections and each of these collections may contain source imagery, labels, or (rarely) both.\n",
    "\n",
    "You can access all collections associated with a dataset using the `collections` property. If you want to access only collections of a certain type, you can use either `collections.source_imagery` or `collections.labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Collections: [<Collection id=sn1_AOI_1_RIO>]\n",
      "Source Imagery Collections: [<Collection id=sn1_AOI_1_RIO>]\n",
      "Labels Collections: [<Collection id=sn1_AOI_1_RIO>]\n"
     ]
    }
   ],
   "source": [
    "# The SpaceNet 1 dataset contains only a single collection...\n",
    "print(f'Total Collections: {spacenet1_dataset.collections}')\n",
    "\n",
    "# ...that catalogs both source imagery and labels\n",
    "print(f'Source Imagery Collections: {spacenet1_dataset.collections.source_imagery}')\n",
    "print(f'Labels Collections: {spacenet1_dataset.collections.labels}')\n",
    "\n",
    "# Note that the IDs are identical,\n",
    "# and that len(dataset.collections) != len(dataset.collections.source_imagery) + len(dataset.collections.labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of these collections is a `radiant_mlhub.Collection` instance. In the next section, we walk through how to work with these `Collection` instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Collection` Class\n",
    "\n",
    "Using the `radiant_mlhub.Collection` class is the recommended method for working with Collections from the Radiant MLHub API (see [Low-Level Client](#Low-Level-Client) docs below for how to work with these Collections as Python data types).\n",
    "\n",
    "The `radiant_mlhub.Collection` class inherits from the [`pystac.Collection` class](https://pystac.readthedocs.io/en/latest/api.html#collection) and adds a few convenience methods for working with the Radiant MLHub API:\n",
    "\n",
    "* `Collection.list`: A class method for listing the collections available from the API\n",
    "* `Collection.fetch`: A class method for fetching a collection from the API by ID."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Collections\n",
    "\n",
    "The `Collection.list` method is a generator that yields `Collection` instances. We can use the attributes provided by `pystac.Collection` to inspect the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_african_crops_kenya_01_labels: African Crops Kenya\n",
      "ref_african_crops_kenya_01_source: African Crops Kenya Source Imagery\n",
      "ref_african_crops_tanzania_01_labels: African Crops Tanzania\n",
      "ref_african_crops_tanzania_01_source: African Crops Tanzania Source Imagery\n",
      "ref_african_crops_uganda_01_labels: African Crops Uganda\n",
      "ref_african_crops_uganda_01_source: African Crops Uganda Source Imagery\n",
      "microsoft_chesapeake_landsat_leaf_off: Microsoft Chesapeake Landsat 8 Leaf-Off Composite\n",
      "microsoft_chesapeake_buildings: Microsoft Chesapeake Buildings\n",
      "sn4_AOI_6_Atlanta: SpaceNet 4 Atlanta Chipped Training Dataset\n",
      "ref_african_crops_kenya_02_labels: No Description\n"
     ]
    }
   ],
   "source": [
    "collections = Collection.list()\n",
    "\n",
    "# Print info for the first 10 collections\n",
    "for collection in it.islice(collections, 10):\n",
    "    print(f'{collection.id}: {collection.description}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch a Collection\n",
    "\n",
    "If you have the ID of a collection, you can also fetch it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'assets': {},\n",
      " 'description': 'BigEarthNet v1.0',\n",
      " 'extent': {'spatial': {'bbox': [[-9.00023345437725,\n",
      "                                  1.7542686833884724,\n",
      "                                  83.44558248555553,\n",
      "                                  68.02168200047284]]},\n",
      "            'temporal': {'interval': [['2017-06-13T10:10:31Z',\n",
      "                                       '2018-05-29T11:54:01Z']]}},\n",
      " 'id': 'bigearthnet_v1_labels',\n",
      " 'keywords': [],\n",
      " 'license': 'CDLA-Permissive-1.0',\n",
      " 'links': [{'href': 'https://api.radiant.earth/mlhub/v1/collections/bigearthnet_v1_labels',\n",
      "            'rel': 'self',\n",
      "            'type': 'application/json'},\n",
      "           {'href': 'https://api.radiant.earth/mlhub/v1',\n",
      "            'rel': 'root',\n",
      "            'type': 'application/json'}],\n",
      " 'properties': {},\n",
      " 'providers': [{'name': 'BigEarthNet',\n",
      "                'roles': ['processor', 'licensor'],\n",
      "                'url': 'https://api.radiant.earth/mlhub/v1/download/gAAAAABgIX8K2iFTj0GC3CNdQ3_8L5bV8f5WLtm49yMoHlm89N6EjB3nBnvS24AVhWtvD8fgtRda8eEh0jkegjjPydBcTOk1B_9NUu-aU2QgHkdKxZLtwMsY-FIa9Y9pLA5JKyTBOczq53OWqrmhIuY4VcAYzfy1-6lhPea4Ycf_churOCHKY6zzRg01YW22Vy2wbjCL6wdO0acZFYjn86BHLuAswuPmQL3HaO-8FVSatMeH5-wK6v0='}],\n",
      " 'sci:citation': 'G. Sumbul, M. Charfuelan, B. Demir, V. Markl, \"BigEarthNet: '\n",
      "                 'A Large-Scale Benchmark Archive for Remote Sensing Image '\n",
      "                 'Understanding\", IEEE International Geoscience and Remote '\n",
      "                 'Sensing Symposium, pp. 5901-5904, Yokohama, Japan, 2019.',\n",
      " 'stac_extensions': ['label', 'scientific'],\n",
      " 'stac_version': '1.0.0-beta.2',\n",
      " 'summaries': {},\n",
      " 'title': None}\n"
     ]
    }
   ],
   "source": [
    "bigearthnet_labels = Collection.fetch('bigearthnet_v1_labels')\n",
    "\n",
    "pprint(bigearthnet_labels.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download a Collection Archive\n",
    "\n",
    "The simplest way to get assets (imagery and/or labels) associated with a Collection is to download the full archive for that Collection. Collection archives are gzipped tarballs containing all assets for a given collection. You can download these archives using the `Collection.download` method:\n",
    "\n",
    "**Note that if you are running this notebook remotely using Binder this archive will be downloaded to the remote file system and not your local machine. To download locally, clone the repo and run this notebook locally.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d7cb8597ce04289abeeb64ac769ae81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/173.0 [00:00<?, ?M/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jduckworth/Code/ml-hub/radiant-mlhub/examples/bigearthnet_v1_labels.tar.gz (173.0 MB)\n"
     ]
    }
   ],
   "source": [
    "# Download to the current working directory\n",
    "archive_path = bigearthnet_labels.download('.')\n",
    "\n",
    "# Print the path and file size\n",
    "size_gb = round(archive_path.stat().st_size / 1000000., 1)\n",
    "print(f'{str(archive_path)} ({size_gb} MB)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low-Level Client\n",
    "\n",
    "The low-level client functions also provide a way of interacting with the Radiant MLHub API `/collections` and `/dataset` endpoints using Python. These methods return native Python data types (e.g. `list`, `dict`, etc.) rather than the `Collection` and `Datast` instances documented above.\n",
    "\n",
    "All low-level client functions are contained in the `radiant_mlhub.client` module (imported above). All of these methods accept the `profile` and `api_key` keyword arguments, which are passed directly to `radiant_mlhub.get_session`, if provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Datasets\n",
    "\n",
    "You can use the `list_datasets` method to loop through all of the available datasets. This method makes requests to the `/datasets` endpoint, which returns paginated responses (with a `next` link). The `list_datasets` method will continue to make requests for the next page of responses, as needed, and yields a dictionary for each dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'collections': [{'id': 'bigearthnet_v1_source', 'types': ['source_imagery']},\n",
      "                 {'id': 'bigearthnet_v1_labels', 'types': ['labels']}],\n",
      " 'id': 'bigearthnet_v1',\n",
      " 'title': 'BigEarthNet'}\n"
     ]
    }
   ],
   "source": [
    "datasets = client.list_datasets()\n",
    "\n",
    "first_dataset = datasets[0]\n",
    "pprint(first_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Dataset\n",
    "\n",
    "You can use the `get_dataset` method to fetch a dataset by ID. This method returns a Python dictionary representing the dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'collections': [{'id': 'bigearthnet_v1_source', 'types': ['source_imagery']},\n",
      "                 {'id': 'bigearthnet_v1_labels', 'types': ['labels']}],\n",
      " 'id': 'bigearthnet_v1',\n",
      " 'title': 'BigEarthNet'}\n"
     ]
    }
   ],
   "source": [
    "bigearthnet_dataset = client.get_dataset('bigearthnet_v1')\n",
    "pprint(bigearthnet_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Collections\n",
    "\n",
    "You can use the `radiant_mlhub.client.list_collections` method to loop through all of the collections available through the Radiant MLHub API. This method makes requests to the `/collections` endpoint, which returns paginated responses. The `list_collections` method will make paginated requests to the endpoint to retrieve all collections and will yield these collections as Python dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_african_crops_kenya_01_labels: African Crops Kenya\n",
      "ref_african_crops_kenya_01_source: African Crops Kenya Source Imagery\n",
      "ref_african_crops_tanzania_01_labels: African Crops Tanzania\n",
      "ref_african_crops_tanzania_01_source: African Crops Tanzania Source Imagery\n",
      "ref_african_crops_uganda_01_labels: African Crops Uganda\n",
      "ref_african_crops_uganda_01_source: African Crops Uganda Source Imagery\n",
      "microsoft_chesapeake_landsat_leaf_off: Microsoft Chesapeake Landsat 8 Leaf-Off Composite\n",
      "microsoft_chesapeake_buildings: Microsoft Chesapeake Buildings\n",
      "sn4_AOI_6_Atlanta: SpaceNet 4 Atlanta Chipped Training Dataset\n",
      "ref_african_crops_kenya_02_labels: No Description\n"
     ]
    }
   ],
   "source": [
    "collections = client.list_collections()\n",
    "\n",
    "for collection in it.islice(collections, 10):\n",
    "    print(collection['id'] + \": \" + collection['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch a Collection\n",
    "\n",
    "You can use the `get_collection` method to fetch a collection by ID. This method returns a Python dictionary representing the collection object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'BigEarthNet v1.0',\n",
      " 'extent': {'spatial': {'bbox': [[-9.00023345437725,\n",
      "                                  1.7542686833884724,\n",
      "                                  83.44558248555553,\n",
      "                                  68.02168200047284]]},\n",
      "            'temporal': {'interval': [['2017-06-13T10:10:31Z',\n",
      "                                       '2018-05-29T11:54:01Z']]}},\n",
      " 'id': 'bigearthnet_v1_source',\n",
      " 'keywords': [],\n",
      " 'license': 'CDLA-Permissive-1.0',\n",
      " 'links': [{'href': 'https://api.radiant.earth/mlhub/v1/collections/bigearthnet_v1_source',\n",
      "            'rel': 'self',\n",
      "            'title': None,\n",
      "            'type': 'application/json'},\n",
      "           {'href': 'https://api.radiant.earth/mlhub/v1',\n",
      "            'rel': 'root',\n",
      "            'title': None,\n",
      "            'type': 'application/json'}],\n",
      " 'properties': {},\n",
      " 'providers': [{'description': None,\n",
      "                'name': 'BigEarthNet',\n",
      "                'roles': ['processor', 'licensor'],\n",
      "                'url': 'https://api.radiant.earth/mlhub/v1/download/gAAAAABgIX8diLbpPsIYyPWy_7HQDgd7mkx--aoNMtqm3OjapV6_5-UpfbCoyoU74Yj_0aN25gihDr-RAt0WLU46cGaMXIv9Pp06lC8_2wyfww8x9TKK_dTuxqBFf6OlDITmueJSETJ7IhVHVs73Udsv3Ve-TCY0HQI1aO4eEBegY-eRgssdQP9XGIDP0-dCju5YFS8x8BW-TG89UvxQGS-uX-XObezFXiO-gTyAfRToDo4VvfNlMNY='}],\n",
      " 'sci:citation': 'G. Sumbul, M. Charfuelan, B. Demir, V. Markl, \"BigEarthNet: '\n",
      "                 'A Large-Scale Benchmark Archive for Remote Sensing Image '\n",
      "                 'Understanding\", IEEE International Geoscience and Remote '\n",
      "                 'Sensing Symposium, pp. 5901-5904, Yokohama, Japan, 2019.',\n",
      " 'stac_extensions': ['eo', 'scientific'],\n",
      " 'stac_version': '1.0.0-beta.2',\n",
      " 'summaries': {},\n",
      " 'title': None}\n"
     ]
    }
   ],
   "source": [
    "bigearthnet_v1_source = client.get_collection('bigearthnet_v1_source')\n",
    "pprint(bigearthnet_v1_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
